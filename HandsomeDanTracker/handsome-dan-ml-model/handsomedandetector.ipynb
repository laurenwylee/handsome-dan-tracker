{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenwylee/handsome-dan-tracker/blob/main/handsome-dan-ml-model/handsomedandetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9cSlQ-HCNw3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from google.colab import files\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Enable CUDA debugging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIUi0X7A7qSJ",
        "outputId": "2626dd65-79e7-4490-9d74-14839f9dadf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7454"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# clear storage\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFNEFcivRent"
      },
      "outputs": [],
      "source": [
        "class HandsomeDanDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # collect image file names\n",
        "        self.dan_imgs = list(sorted(os.listdir(os.path.join(root, \"handsomedanpics\"))))\n",
        "        self.non_dan_imgs = list(sorted(os.listdir(os.path.join(root, \"nondanpics\"))))\n",
        "\n",
        "        # filter only .jpg files with corresponding .xml files for handsomedanpics\n",
        "        self.dan_imgs = [\n",
        "            f for f in self.dan_imgs if f.endswith(\".jpg\") and os.path.exists(os.path.join(root, \"handsomedanpics\", f.replace(\".jpg\", \".xml\")))\n",
        "        ]\n",
        "\n",
        "        # separate non-Dan images with and without dogs\n",
        "        self.non_dan_dog_imgs = [\n",
        "            f for f in self.non_dan_imgs if f.endswith(\".jpg\") and os.path.exists(os.path.join(root, \"nondanpics\", f.replace(\".jpg\", \".xml\")))\n",
        "        ]\n",
        "        self.non_dan_random_imgs = [f for f in self.non_dan_imgs if f.endswith(\".jpg\") and f not in self.non_dan_dog_imgs]\n",
        "        # self.non_dan_random_imgs = [f for f in self.non_dan_imgs if f.endswith(\".jpg\")]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # handsome dan pics\n",
        "        if idx < len(self.dan_imgs):\n",
        "            img_path = os.path.join(self.root, \"handsomedanpics\", self.dan_imgs[idx])\n",
        "            label_path = img_path.replace(\".jpg\", \".xml\")\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            tree = ET.parse(label_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # if valid bounding box\n",
        "            boxes = []\n",
        "            labels = []\n",
        "            for member in root.findall(\"object\"):\n",
        "                bndbox = member.find(\"bndbox\")\n",
        "                xmin = int(bndbox.find(\"xmin\").text)\n",
        "                ymin = int(bndbox.find(\"ymin\").text)\n",
        "                xmax = int(bndbox.find(\"xmax\").text)\n",
        "                ymax = int(bndbox.find(\"ymax\").text)\n",
        "                if xmin < xmax and ymin < ymax:\n",
        "                    boxes.append([xmin, ymin, xmax, ymax])\n",
        "                    labels.append(1)  # 1 for Handsome Dan\n",
        "\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "            image_id = torch.tensor([idx])\n",
        "            target = {\n",
        "                \"boxes\": boxes,\n",
        "                \"labels\": labels,\n",
        "                \"image_id\": image_id\n",
        "            }\n",
        "        else:\n",
        "            # non-dan dog pics\n",
        "            non_dan_idx = idx - len(self.dan_imgs)\n",
        "            if non_dan_idx < len(self.non_dan_dog_imgs):\n",
        "                img_path = os.path.join(self.root, \"nondanpics\", self.non_dan_dog_imgs[non_dan_idx])\n",
        "                label_path = img_path.replace(\".jpg\", \".xml\")\n",
        "                img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "                tree = ET.parse(label_path)\n",
        "                root = tree.getroot()\n",
        "\n",
        "                boxes = []\n",
        "                labels = []\n",
        "                for member in root.findall(\"object\"):\n",
        "                    bndbox = member.find(\"bndbox\")\n",
        "                    xmin = int(bndbox.find(\"xmin\").text)\n",
        "                    ymin = int(bndbox.find(\"ymin\").text)\n",
        "                    xmax = int(bndbox.find(\"xmax\").text)\n",
        "                    ymax = int(bndbox.find(\"ymax\").text)\n",
        "                    if xmin < xmax and ymin < ymax:\n",
        "                        boxes.append([xmin, ymin, xmax, ymax])\n",
        "                        labels.append(2)  # 2 for other dogs\n",
        "\n",
        "                boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "                labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "                image_id = torch.tensor([idx])\n",
        "                target = {\n",
        "                    \"boxes\": boxes,\n",
        "                    \"labels\": labels,\n",
        "                    \"image_id\": image_id\n",
        "                }\n",
        "            else:\n",
        "              # random pics, no bounding box\n",
        "              non_dan_random_idx = non_dan_idx - len(self.non_dan_dog_imgs)\n",
        "              # non_dan_random_idx = idx - len(self.dan_imgs)\n",
        "              img_path = os.path.join(self.root, \"nondanpics\", self.non_dan_random_imgs[non_dan_random_idx])\n",
        "              img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "              boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "              labels = torch.zeros((0,), dtype=torch.int64)\n",
        "              image_id = torch.tensor([idx])\n",
        "              target = {\n",
        "                  \"boxes\": boxes,\n",
        "                  \"labels\": labels,\n",
        "                  \"image_id\": image_id\n",
        "              }\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dan_imgs) + len(self.non_dan_dog_imgs) + len(self.non_dan_random_imgs)\n",
        "        # return len(self.dan_imgs )+ len(self.non_dan_random_imgs)\n",
        "\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = [T.ToTensor()]\n",
        "    # data augmentations\n",
        "    if train:\n",
        "        transforms.extend([\n",
        "            T.RandomHorizontalFlip(0.5),\n",
        "            T.RandomVerticalFlip(0.5),\n",
        "            # T.RandomRotation(degrees=30),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "            # T.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0))\n",
        "        ])\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZlByN6cmZQ4"
      },
      "outputs": [],
      "source": [
        "# create a folder in your google drive called data\n",
        "# data should have /data/training/ and /data/validation/\n",
        "# each of these should have a folder for handsomedanpics and nondanpics\n",
        "# every photo in handsomedanpics should have a bounding box around handsome dan and a corresponding xml file\n",
        "# every photo of a dog in nondanpics should have a bounding box around the dan and a corresponding xml file --> done by Stanford dogs dataset on Kaggle\n",
        "!cp -r drive/MyDrive/data /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSfMDBBLRjx6"
      },
      "outputs": [],
      "source": [
        "# load training and testing datasets\n",
        "dataset = HandsomeDanDataset('/content/data/train', get_transform(train=True))\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "dataset_val = HandsomeDanDataset('/content/data/validation', get_transform(train=False))\n",
        "data_loader_val = torch.utils.data.DataLoader(\n",
        "    dataset_val, batch_size=4, shuffle=False, num_workers=4, collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR1VvOolR6LO",
        "outputId": "415ede1a-7426-4b5a-d9dd-7bb0f91bacee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# use pretrained model, all we are doing is adjusting weights and finetuning since we don't have a super large dataset\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 3) # 3 classes for random pics, handsome dan, other dogs\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#     print(torch.cuda.get_device_name(0))\n",
        "#     print('Memory Usage:')\n",
        "#     print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "#     print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# adjust class weights (random, HD, other dogs)\n",
        "class_weights = torch.tensor([1.2, 1.5, 1.0]).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# set hyperparameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f-JAPsOR9-M",
        "outputId": "e45a716c-ca9c-4e6e-b954-e764792bca07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 348/348 [08:04<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 1, Loss: 0.1866998724243336, Precision: 1.0, Recall: 0.9230769230769231, F1: 0.9600000000000001, Time: 488.59 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 348/348 [08:00<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 2, Loss: 0.13449467340719767, Precision: 1.0, Recall: 1.0, F1: 1.0, Time: 484.59 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 348/348 [08:04<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 3, Loss: 0.12417328619430291, Precision: 0.8666666666666667, Recall: 1.0, F1: 0.9285714285714286, Time: 487.88 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 348/348 [08:01<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 4, Loss: 0.11839266719788998, Precision: 1.0, Recall: 1.0, F1: 1.0, Time: 485.00 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 348/348 [08:01<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 5, Loss: 0.11673090788642822, Precision: 0.9285714285714286, Recall: 1.0, F1: 0.962962962962963, Time: 485.14 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 348/348 [08:08<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 6, Loss: 0.11667563989169724, Precision: 1.0, Recall: 1.0, F1: 1.0, Time: 492.59 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 348/348 [07:56<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 7, Loss: 0.11538437122329213, Precision: 1.0, Recall: 1.0, F1: 1.0, Time: 480.58 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 348/348 [07:56<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 8, Loss: 0.11528274099524508, Precision: 1.0, Recall: 1.0, F1: 1.0, Time: 480.66 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 348/348 [08:01<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 9, Loss: 0.11727625229021256, Precision: 1.0, Recall: 1.0, F1: 1.0, Time: 485.54 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 348/348 [08:02<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Labels\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Epoch: 10, Loss: 0.11538999809765782, Precision: 1.0, Recall: 1.0, F1: 1.0, Time: 486.17 sec\n"
          ]
        }
      ],
      "source": [
        "# 10 epochs, evaluate at end, set min confidence level for handsome dan to .3\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, targets in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        try:\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += losses.item()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            continue\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader_val:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            outputs = model(images)\n",
        "            for target, output in zip(targets, outputs):\n",
        "                labels = target[\"labels\"].cpu().numpy()\n",
        "                all_labels.append(1 if 1 in labels else 0)\n",
        "                preds = output[\"labels\"].cpu().numpy()\n",
        "                scores = output[\"scores\"].cpu().numpy()\n",
        "                if len(preds) > 0 and any(pred == 1 and score > 0.3 for pred, score in zip(preds, scores)):\n",
        "                    all_preds.append(1)\n",
        "                else:\n",
        "                    all_preds.append(0)\n",
        "    print(\"Predictions\")\n",
        "    print(all_preds)\n",
        "    print(\"Labels\")\n",
        "    print(all_labels)\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {epoch_loss/len(data_loader)}, Precision: {precision}, Recall: {recall}, F1: {f1}, Time: {epoch_time:.2f} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate cell to isolate evaluation\n",
        "\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for images, targets in data_loader:\n",
        "        images = list(img.to(device) for img in images)\n",
        "        outputs = model(images)\n",
        "        for target, output in zip(targets, outputs):\n",
        "            labels = target[\"labels\"].cpu().numpy()\n",
        "            all_labels.append(1 if 1 in labels else 0)\n",
        "            preds = output[\"labels\"].cpu().numpy()\n",
        "            scores = output[\"scores\"].cpu().numpy()\n",
        "            if len(preds) > 0 and any(pred == 1 and score > 0.3 for pred, score in zip(preds, scores)):\n",
        "                all_preds.append(1)\n",
        "            else:\n",
        "                all_preds.append(0)\n",
        "print(\"Predictions\")\n",
        "print(all_preds)\n",
        "print(\"Labels\")\n",
        "print(all_labels)\n",
        "\n",
        "precision = precision_score(all_labels, all_preds)\n",
        "recall = recall_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
      ],
      "metadata": {
        "id": "pTIKdwMpbWq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589cc90b-a6f3-43ef-b319-9da8dffa64f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions\n",
            "[0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "Labels\n",
            "[1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "Precision: 0.8350730688935282, Recall: 0.9324009324009324, F1: 0.881057268722467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# true pos and true neg levels\n",
        "totX = 0\n",
        "totY = 0\n",
        "for i in range(len(all_preds)):\n",
        "  if all_labels[i] == 1 and all_preds[i] == 1:\n",
        "    totX += 1\n",
        "  if all_labels[i] == 1:\n",
        "    totY += 1\n",
        "print(totX/totY)\n",
        "\n",
        "totA = 0\n",
        "totB = 0\n",
        "for i in range(len(all_preds)):\n",
        "  if all_labels[i] == 0 and all_preds[i] == 0:\n",
        "    totA += 1\n",
        "  if all_labels[i] == 0:\n",
        "    totB += 1\n",
        "print(totA/totB)"
      ],
      "metadata": {
        "id": "zMeOBmFhviyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea565d8-3660-4f71-9460-d57652ad03dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9324009324009324\n",
            "0.9178794178794178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3omb7vISxbr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "965fadc8-279d-48af-f1e6-1a6f436a3d2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e422639f-3e11-4452-9da9-c4aa9863505b\", \"handsome_dan_detector.pth\", 165751934)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# save and downlaod model\n",
        "torch.save(model.state_dict(), 'handsome_dan_detector.pth')\n",
        "files.download('handsome_dan_detector.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1bk3Z9ETIQyVbTjqSQ9bstqGaZNWFryBF",
      "authorship_tag": "ABX9TyPjfP5VeM3Z5VaIHa1Juhk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}